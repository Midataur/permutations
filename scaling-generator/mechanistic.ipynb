{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import wandb\n",
    "from utilities import *\n",
    "from config import *\n",
    "from dataloading import *\n",
    "from tqdm import tqdm\n",
    "from transformer import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup the model\n",
    "model = BigramLanguageModel()\n",
    "\n",
    "# cuda? (gpu)\n",
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "\n",
    "# send to gpu (maybe)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# optionally: load the model\n",
    "filename = PATH + \"/model/\" + MODELNAME + \".pth\"\n",
    "if os.path.isfile(filename):\n",
    "    model.load_state_dict(torch.load(filename, map_location=torch.device(device)))\n",
    "\n",
    "os.path.isfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4,  9,  2,  5,  6,  8,  0,  7, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "seq = val_seqs[k]\n",
    "perm = val_perms[k]\n",
    "perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 9, 2, 5, 6, 8, 0, 7, 10, 11, 12, 13, 14, 15]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.generate(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m tqdm(val_dataloader):\n\u001b[1;32m     13\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m---> 15\u001b[0m     \u001b[39m0\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     17\u001b[0m     \u001b[39m# calculate the val accuracy\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     accuracy \u001b[39m=\u001b[39m calculate_accuracy(outputs, targets)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Calculate and print accuracy after each epoch\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # calculate validation stats\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    num_batches = 0\n",
    "\n",
    "    print(\"Evaluating...\")\n",
    "    for inputs, targets in tqdm(val_dataloader):\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        0/0\n",
    "\n",
    "        # calculate the val accuracy\n",
    "        accuracy = calculate_accuracy(outputs, targets)\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "        # Calculate the val loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    average_accuracy = total_accuracy / num_batches\n",
    "    val_loss = total_loss / num_batches\n",
    "\n",
    "    metrics = {\n",
    "        \"validation_accuracy\": average_accuracy,\n",
    "        \"loss\": val_loss,\n",
    "        \"training_accuracy\": average_train_accuracy,\n",
    "        \"training_loss\": train_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  0,  0,  1,  0,  0,  0,  0,  1,  1,  1,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  0,  1,  1,  0,  0,  0,  1,\n",
       "         1,  0,  0,  0,  1,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "         0,  0,  0,  1,  0,  0,  1,  0,  0,  1,  0,  1,  1,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,\n",
       "         0,  1,  0,  0,  0,  1,  1,  1,  0,  0, 19,  5,  3, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6464.0293, -6464.0288, -6445.1235, -6450.2651, -6455.7666, -6448.2124,\n",
       "        -6398.2354, -6451.0259, -6451.6304, -6452.4790, -6443.1245, -6442.4336,\n",
       "        -6453.8066, -6463.5933, -6480.9731, -6465.3164, -6468.9014, -6464.4336,\n",
       "        -6464.0283, -6464.0308, -6466.9629])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.softmax(outputs)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4,  9,  2,  5,  6,  8,  0,  7, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_perms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "\n",
    "def np_to_mathematica(array, copy=True):\n",
    "    formatted = str(array.tolist()).replace(\"[\", \"{\").replace(\"]\", \"}\")\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(np_to_mathematica(embedding_pca))\n",
    "print(\"Copied!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "embedding = np.array(model.module.token_embedding_table.weight.cpu().detach().numpy())\n",
    "pos_embedding = np.array(model.module.position_embedding.weight.cpu().detach().numpy())\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(embedding)\n",
    "\n",
    "embedding_pca = pca.transform(embedding)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(pos_embedding)\n",
    "\n",
    "pos_embedding_pca = pca.transform(pos_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "similarity = []\n",
    "\n",
    "for x in embedding:\n",
    "    row = []\n",
    "    for y in embedding:\n",
    "        row.append(np.dot(x, y))\n",
    "    similarity.append(row)\n",
    "\n",
    "px.imshow(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(pos_embedding[MAX_LENGTH], embedding[START_PREDICTION_TOKEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_transposition(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 30\n",
    "\n",
    "for pos1, x in enumerate(embedding):\n",
    "    for pos2, y in enumerate(embedding):\n",
    "        if np.dot(x, y) > threshold and pos1 != pos2:\n",
    "            print(\"x\", pos1, \"y\", pos2, \"dot\", np.dot(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.module.token_embedding_table.weight.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.no_grad()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate validation stats\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_accuracy = 0.0\n",
    "total_loss = 0.0\n",
    "\n",
    "num_batches = 0\n",
    "\n",
    "print(\"Evaluating...\")\n",
    "for inputs, targets in tqdm(val_dataloader):\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # calculate the val accuracy\n",
    "    accuracy = calculate_accuracy(outputs, targets)\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "    # Calculate the val loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    total_loss += loss.item()\n",
    "    num_batches += 1\n",
    "\n",
    "average_accuracy = total_accuracy / num_batches\n",
    "val_loss = total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# use gpu for processing\n",
    "if cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "# create an initial input\n",
    "input_tensor = torch.ones(block_size, dtype=int).to(dev)\n",
    "input_tensor *= TO_PREDICT_TOKEN\n",
    "input_tensor[:len(seq)] = torch.tensor(seq, dtype=int).to(dev)\n",
    "input_tensor[len(seq)] = START_PREDICTION_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(input_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(model(input_tensor.unsqueeze(0)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tensor = torch.zeros(block_size, dtype=int).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [1,2,3,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tensor[:len(sequence)] = torch.tensor(sequence, dtype=int).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.ones(block_size, dtype=int).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor *= TO_PREDICT_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
