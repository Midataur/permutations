{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100000it [00:07, 12932.57it/s]\n",
      "Loading data: 10000it [00:00, 38236.37it/s]\n",
      "Loading data: 5000it [00:00, 38271.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import wandb\n",
    "from utilities import *\n",
    "from config import *\n",
    "from dataloading import *\n",
    "from tqdm import tqdm\n",
    "from transformer import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the model\n",
    "model = BigramLanguageModel()\n",
    "\n",
    "# cuda? (gpu)\n",
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "  \n",
    "# send to gpu (maybe)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# optionally: load the model\n",
    "filename = PATH + \"/model/\" + MODELNAME + \".pth\"\n",
    "if os.path.isfile(filename):\n",
    "    model.load_state_dict(torch.load(filename, map_location=torch.device(device)))\n",
    "\n",
    "os.path.isfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(model.module.position_embedding(torch.arange(block_size)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from math import sin, cos, tau\n",
    "\n",
    "# generate embedding\n",
    "embedding = []\n",
    "\n",
    "period = 10\n",
    "N = 2*period\n",
    "\n",
    "for x in range(N):\n",
    "    embedding.append(np.array([cos((tau*x)/period), sin((tau*x)/period)]))\n",
    "\n",
    "similarity = []\n",
    "\n",
    "for x in embedding:\n",
    "    row = []\n",
    "    for y in embedding:\n",
    "        row.append(np.dot(x, y)/(np.linalg.norm(x)*np.linalg.norm(y)))\n",
    "    similarity.append(row)\n",
    "\n",
    "figure = px.imshow(similarity, title=f\"Periodic embedding similarity matrix\")\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "embedding = model.module.position_embedding(torch.arange(block_size)).detach().numpy()\n",
    "\n",
    "similarity = []\n",
    "\n",
    "for x in embedding:\n",
    "    row = []\n",
    "    for y in embedding:\n",
    "        row.append(np.dot(x, y)/(np.linalg.norm(x)*np.linalg.norm(y)))\n",
    "    similarity.append(row)\n",
    "\n",
    "figure = px.imshow(similarity, title=f\"{MODELNAME} position embedding similarity matrix\")\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perms.apppend(list(range(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embedding = model.module.position_embedding(torch.arange(block_size)).numpy()\n",
    "\n",
    "pca = PCA(n_components=37)\n",
    "pca_reduced = pca.fit_transform(embedding)\n",
    "\n",
    "tsne = TSNE()\n",
    "tsne_reduced = tsne.fit_transform(pca_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(\n",
    "    x=tsne_reduced[:,0], \n",
    "    y=tsne_reduced[:,1], \n",
    "    color=[\"input\" for x in range(20)] + [\"seperator\"] + [\"output\" for x in range(16)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({\"image\": wandb.Image(np.array(similarity))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plausible = 0\n",
    "\n",
    "for perm in tqdm(test_perms):\n",
    "    correct = 0\n",
    "\n",
    "    for pos, char in enumerate(perm):\n",
    "        if char == pos:\n",
    "            correct += 1\n",
    "    \n",
    "    if correct >= 6:\n",
    "        plausible += 1\n",
    "\n",
    "plausible/len(test_perms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test_dataloader:\n",
    "    break\n",
    "\n",
    "model(x[0][0].reshape((1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x[0][0].reshape((1,-1))).argsort(dim=1, descending=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15+num_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = float(\"inf\")\n",
    "\n",
    "for perm in test_perms:\n",
    "    fixed = 0\n",
    "\n",
    "    for pos, char in enumerate(perm):\n",
    "        fixed += pos == char\n",
    "    \n",
    "    best = min(fixed, best)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "embedding = model.module.token_embedding_table(torch.arange(vocab_size)).detach().cpu().numpy()\n",
    "\n",
    "similarity = []\n",
    "\n",
    "for x in embedding:\n",
    "    row = []\n",
    "    for y in embedding:\n",
    "        row.append(np.dot(x, y)/(np.linalg.norm(x)*np.linalg.norm(y)))\n",
    "    similarity.append(row)\n",
    "\n",
    "similarity = np.array(similarity)\n",
    "\n",
    "px.imshow(similarity.round(3), title=f\"{MODELNAME} token embedding similarity matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./embedding_pictures/position/{MODELNAME}.npy\", \"wb\") as file:\n",
    "    np.save(file, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./embedding_pictures/position/{MODELNAME}.npy\", \"rb\") as file:\n",
    "    b = np.load(file)\n",
    "\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next plot is found by taking the embeddings of $s_{i,j}$ at different positions and dotting them together (normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarise(pos1, pos2, d=4):\n",
    "    return torch.tensor([int(x) for x in format(2**(d)*pos1+pos2, f'#0{2*d+2}b')[2:]])\n",
    "\n",
    "def process_tensor(tensor):\n",
    "    return tensor.detach().numpy().reshape(-1)\n",
    "\n",
    "similarity = []\n",
    "\n",
    "digits = 5\n",
    "\n",
    "for swap1 in range(2**(digits-1)):\n",
    "    swap1_slice = []\n",
    "\n",
    "    for swap2 in range(2**(digits-1)):\n",
    "        swap2_slice = []\n",
    "\n",
    "        for x in range(10):\n",
    "            row = []\n",
    "\n",
    "            for y in range(10):\n",
    "                token_embedding = process_tensor(\n",
    "                    model.module.token_embedding_table(binarise(swap1, swap2, digits))\n",
    "                )\n",
    "\n",
    "                vectors = []\n",
    "\n",
    "                for j in (x, y):\n",
    "                    position_embedding = process_tensor(\n",
    "                        model.module.position_embedding(torch.arange(j*digits, (j+2)*digits))\n",
    "                    )\n",
    "\n",
    "                    swap_embedding = token_embedding + position_embedding\n",
    "                    vectors.append(swap_embedding / np.linalg.norm(swap_embedding))\n",
    "                \n",
    "                row.append(np.dot(vectors[0], vectors[1]))\n",
    "            swap2_slice.append(row)\n",
    "        swap1_slice.append(swap2_slice)\n",
    "    similarity.append(swap1_slice)\n",
    "\n",
    "similarity = np.array(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# the following code is chatgpt generated (mostly)\n",
    "\n",
    "def frame_name(i, j):\n",
    "    return f\"swap_{i}_{j}\"\n",
    "\n",
    "# Create initial heatmap (first slice)\n",
    "initial_data = similarity[0, 0]\n",
    "fig = go.Figure(data=go.Heatmap(z=initial_data))\n",
    "\n",
    "zmin = np.min(similarity)\n",
    "zmax = np.max(similarity)\n",
    "\n",
    "# Define frames\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=go.Heatmap(z=similarity[i, j], zmin=zmin, zmax=zmax), \n",
    "        name=frame_name(i, j)\n",
    "    )\n",
    "    for i in range(similarity.shape[0])\n",
    "    for j in range(similarity.shape[1])\n",
    "]\n",
    "\n",
    "# Add frames to the figure\n",
    "fig.frames = frames\n",
    "\n",
    "# Create slider steps for both sliders\n",
    "slider1_steps = [\n",
    "    {\n",
    "        \"args\": [\n",
    "            [frame_name(i, 0)],\n",
    "            {\n",
    "                \"frame\": {\"duration\": 300, \"redraw\": True},\n",
    "                \"mode\": \"immediate\",\n",
    "                \"transition\": {\"duration\": 300},\n",
    "            },\n",
    "        ],\n",
    "        \"label\": f\"Index {i}\",\n",
    "        \"method\": \"animate\",\n",
    "    }\n",
    "    for i in range(similarity.shape[0])\n",
    "]\n",
    "\n",
    "slider2_steps = [\n",
    "    {\n",
    "        \"args\": [\n",
    "            [frame_name(0, j)],\n",
    "            {\n",
    "                \"frame\": {\"duration\": 300, \"redraw\": True},\n",
    "                \"mode\": \"immediate\",\n",
    "                \"transition\": {\"duration\": 300},\n",
    "            },\n",
    "        ],\n",
    "        \"label\": f\"Index {j}\",\n",
    "        \"method\": \"animate\",\n",
    "    }\n",
    "    for j in range(similarity.shape[1])\n",
    "]\n",
    "\n",
    "# Update layout with sliders\n",
    "fig.update_layout(\n",
    "    sliders=[\n",
    "        {\n",
    "            \"currentvalue\": {\n",
    "                \"font\": {\"size\": 10},\n",
    "                \"prefix\": \"Tranposition 1: \",\n",
    "                \"visible\": True,\n",
    "                \"xanchor\": \"center\",\n",
    "            },\n",
    "            \"steps\": slider1_steps,\n",
    "            \"yanchor\": \"top\",\n",
    "            \"xanchor\": \"left\",\n",
    "            \"y\": -0.1\n",
    "        },\n",
    "        {\n",
    "            \"currentvalue\": {\n",
    "                \"font\": {\"size\": 10},\n",
    "                \"prefix\": \"Transposition 2: \",\n",
    "                \"visible\": True,\n",
    "                \"xanchor\": \"center\",\n",
    "            },\n",
    "            \"steps\": slider2_steps,\n",
    "            \"yanchor\": \"top\",\n",
    "            \"xanchor\": \"left\",\n",
    "            \"y\": -0.2\n",
    "        }\n",
    "    ],\n",
    "    xaxis=dict(\n",
    "        scaleanchor=\"y\",\n",
    "        scaleratio=1,\n",
    "        constrain=\"domain\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        scaleanchor=\"x\",\n",
    "        scaleratio=1,\n",
    "        constrain=\"domain\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "\n",
    "digits = 5\n",
    "\n",
    "for swap in range(2**digits):\n",
    "    swap_slice = []\n",
    "\n",
    "    for kindex in range(MAX_TRANS_NUMBER):\n",
    "\n",
    "        token_embedding = model.module.token_embedding_table(binarise(swap, swap+1, digits)).detach().numpy()\n",
    "\n",
    "        matrices = []\n",
    "\n",
    "        for j in (1, kindex):\n",
    "            position_embedding = model.module.position_embedding(torch.arange(j*digits, (j+2)*digits)).detach().numpy()\n",
    "\n",
    "            swap_embedding = token_embedding + position_embedding\n",
    "            matrices.append(swap_embedding)\n",
    "\n",
    "        swap_slice.append(np.dot(matrices[0], np.transpose(matrices[1])))\n",
    "    \n",
    "    similarity.append(swap_slice)\n",
    "\n",
    "similarity = np.array(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swap+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import optional_imports\n",
    "nbformat = optional_imports.get_module(\"nbformat\")\n",
    "print(nbformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"./results/window-7.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = results[\"results\"].to_numpy().astype(int)\n",
    "\n",
    "successes = []\n",
    "failures = []\n",
    "\n",
    "for perm, result in zip(test_perms, num_results):\n",
    "    if result:\n",
    "        successes.append(perm)\n",
    "    else:\n",
    "        failures.append(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "fit = pca.fit_transform(model.module.position_embedding(torch.arange(block_size)).detach().numpy())\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seqs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom ouput tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perm_hybrid(seq, size):\n",
    "    og = list(range(size))\n",
    "\n",
    "    swaps = []\n",
    "\n",
    "    for pos, x in enumerate(seq):\n",
    "        if pos % 2 == 0:\n",
    "            swaps.append([x])\n",
    "        else:\n",
    "            swaps[-1].append(x)\n",
    "    \n",
    "    for x, y in swaps:\n",
    "        og[x], og[y] = og[y], og[x]\n",
    "\n",
    "    return np.array(og)\n",
    "\n",
    "def convert_to_hybrid(seq, size):\n",
    "    new = []\n",
    "    \n",
    "    for char in seq:\n",
    "        new.append(int(char//size))\n",
    "        new.append(int(char%size))\n",
    "    \n",
    "    return new\n",
    "\n",
    "def convert_to_general(seq, size):\n",
    "    new = []\n",
    "\n",
    "    for x, y in zip(seq[::2], seq[1::2]):\n",
    "        new.append(x*size + y)\n",
    "\n",
    "    return new\n",
    "\n",
    "custom = [0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 15]\n",
    "\n",
    "true = get_perm_hybrid(\n",
    "    custom, \n",
    "    16\n",
    ")\n",
    "\n",
    "genned = model.module.generate(\n",
    "    convert_to_general(custom, 16), \n",
    "    force_valid=False, \n",
    "    debug=False\n",
    ")\n",
    "\n",
    "print(\"True: \", true)\n",
    "print(\"Model:\", genned)\n",
    "print(\"Same:\", (true == genned).all())\n",
    "print(\"Sortd:\", np.sort(genned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(20)\n",
    "\n",
    "for x, y in zip(a[::2], a[1::2]):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_general(custom, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0 for x in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong\n",
    "b = torch.tensor([-265.7672, -265.7672, -265.7672, -265.7672, -265.7672, -265.7672,\n",
    "         -265.7672, -265.7672, -265.7672, -265.7672, -265.7672, -265.7672,\n",
    "         -265.7672, -265.7672, -265.7672, -265.7672, -240.0325, -247.6589,\n",
    "         -246.5491, -257.4102, -257.1504, -257.8494, -255.2135, -254.7709,\n",
    "         -253.9813, -256.4985, -256.2157, -261.1152, -266.6082, -258.3374,\n",
    "         -273.0349, -261.6855, -265.7672, -265.7672])\n",
    "\n",
    "import plotly.express as px\n",
    "px.bar(b[16:32]-b[16:32].max()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_fixed_count = []\n",
    "\n",
    "for perm in successes:\n",
    "    fixed_count = 0\n",
    "\n",
    "    for pos, char in enumerate(perm):\n",
    "        if pos == char:\n",
    "            fixed_count += 1\n",
    "    \n",
    "    success_fixed_count.append(fixed_count)\n",
    "\n",
    "sum(success_fixed_count)/len(success_fixed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_fixed_count = []\n",
    "\n",
    "for perm in failures:\n",
    "    fixed_count = 0\n",
    "\n",
    "    for pos, char in enumerate(perm):\n",
    "        if pos == char:\n",
    "            fixed_count += 1\n",
    "    \n",
    "    failure_fixed_count.append(fixed_count)\n",
    "\n",
    "sum(failure_fixed_count)/len(failure_fixed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('win-7-succs.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"successes\"])\n",
    "\n",
    "    for x in success_fixed_count:\n",
    "        writer.writerow([x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('win-7-fails.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"failures\"])\n",
    "\n",
    "    for x in failure_fixed_count:\n",
    "        writer.writerow([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_module(\"nbformat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall rpds-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade notebook jupyter jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "00110100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tokens_to_perm([12,13,14,15,16,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "seq = val_seqs[k]\n",
    "perm = val_perms[k]\n",
    "perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.module.generate(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print accuracy after each epoch\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # calculate validation stats\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    num_batches = 0\n",
    "\n",
    "    print(\"Evaluating...\")\n",
    "    for inputs, targets in tqdm(val_dataloader):\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        0/0\n",
    "\n",
    "        # calculate the val accuracy\n",
    "        accuracy = calculate_accuracy(outputs, targets)\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "        # Calculate the val loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    average_accuracy = total_accuracy / num_batches\n",
    "    val_loss = total_loss / num_batches\n",
    "\n",
    "    metrics = {\n",
    "        \"validation_accuracy\": average_accuracy,\n",
    "        \"loss\": val_loss,\n",
    "        \"training_accuracy\": average_train_accuracy,\n",
    "        \"training_loss\": train_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.softmax(outputs)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "\n",
    "def np_to_mathematica(array, copy=True):\n",
    "    formatted = str(array.tolist()).replace(\"[\", \"{\").replace(\"]\", \"}\")\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(np_to_mathematica(embedding_pca))\n",
    "print(\"Copied!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "embedding = np.array(model.module.token_embedding_table.weight.cpu().detach().numpy())\n",
    "pos_embedding = np.array(model.module.position_embedding.weight.cpu().detach().numpy())\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(embedding)\n",
    "\n",
    "embedding_pca = pca.transform(embedding)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(pos_embedding)\n",
    "\n",
    "pos_embedding_pca = pca.transform(pos_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "similarity = []\n",
    "\n",
    "for x in embedding:\n",
    "    row = []\n",
    "    for y in embedding:\n",
    "        row.append(np.dot(x, y))\n",
    "    similarity.append(row)\n",
    "\n",
    "px.imshow(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(pos_embedding[MAX_LENGTH], embedding[START_PREDICTION_TOKEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_transposition(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 30\n",
    "\n",
    "for pos1, x in enumerate(embedding):\n",
    "    for pos2, y in enumerate(embedding):\n",
    "        if np.dot(x, y) > threshold and pos1 != pos2:\n",
    "            print(\"x\", pos1, \"y\", pos2, \"dot\", np.dot(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(model.module.token_embedding_table.weight.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.no_grad()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate validation stats\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_accuracy = 0.0\n",
    "total_loss = 0.0\n",
    "\n",
    "num_batches = 0\n",
    "\n",
    "print(\"Evaluating...\")\n",
    "for inputs, targets in tqdm(val_dataloader):\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # calculate the val accuracy\n",
    "    accuracy = calculate_accuracy(outputs, targets)\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "    # Calculate the val loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    total_loss += loss.item()\n",
    "    num_batches += 1\n",
    "\n",
    "average_accuracy = total_accuracy / num_batches\n",
    "val_loss = total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# use gpu for processing\n",
    "if cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "# create an initial input\n",
    "input_tensor = torch.ones(block_size, dtype=int).to(dev)\n",
    "input_tensor *= TO_PREDICT_TOKEN\n",
    "input_tensor[:len(seq)] = torch.tensor(seq, dtype=int).to(dev)\n",
    "input_tensor[len(seq)] = START_PREDICTION_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(input_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(model(input_tensor.unsqueeze(0)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tensor = torch.zeros(block_size, dtype=int).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [1,2,3,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tensor[:len(sequence)] = torch.tensor(sequence, dtype=int).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.ones(block_size, dtype=int).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor *= TO_PREDICT_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretty pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./embedding_pictures/position/torn-1.0.npy\", \"rb\") as file:\n",
    "    pos_pictures = np.load(file)\n",
    "\n",
    "with open(\"./embedding_pictures/token/torn-1.0.npy\", \"rb\") as file:\n",
    "    token_pictures = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    return px.imshow(\n",
    "        image, \n",
    "        animation_frame=0, \n",
    "        zmin=image.min(),\n",
    "        zmax=image.max()\n",
    "    )\n",
    "\n",
    "show_image(token_pictures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
